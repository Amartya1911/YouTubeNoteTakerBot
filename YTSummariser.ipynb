{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNaL7sIpvYoZ9v2eNthiaa8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f241c6a04e774bd686fa0bc27b61e59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00e1f9cc48ae4c78a00623ad72a4ceaa",
              "IPY_MODEL_a95d3c4728e74308b069243579993afe",
              "IPY_MODEL_4d47cdef5335489d927bcb1290597965"
            ],
            "layout": "IPY_MODEL_d6aa2017b7ea478392b92ab5a84939f8"
          }
        },
        "00e1f9cc48ae4c78a00623ad72a4ceaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b47b2e548341c2b498066e00eb2baa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b642dc1a3a814e2a915a710971e80d9f",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "a95d3c4728e74308b069243579993afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b724adb27e4325ae70da63ad4d79db",
            "max": 511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25c76c6a6ad440dc96c46d5b4b2cdf34",
            "value": 511
          }
        },
        "4d47cdef5335489d927bcb1290597965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3706cce8285740ffbb44ffbfba09c8db",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a53858b1fbaf481b82fa3f4a84ea1b48",
            "value": "‚Äá511/511‚Äá[00:01&lt;00:00,‚Äá320.09it/s,‚ÄáMaterializing‚Äáparam=model.encoder.layers.11.self_attn_layer_norm.weight]"
          }
        },
        "d6aa2017b7ea478392b92ab5a84939f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b47b2e548341c2b498066e00eb2baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b642dc1a3a814e2a915a710971e80d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44b724adb27e4325ae70da63ad4d79db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c76c6a6ad440dc96c46d5b4b2cdf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3706cce8285740ffbb44ffbfba09c8db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53858b1fbaf481b82fa3f4a84ea1b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amartya1911/YTSummariser/blob/main/YTSummariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVaRoc4SL94W",
        "outputId": "847f5563-c817-4b5d-ce97-1926641ac875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu128)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2026.1.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U youtube-transcript-api transformers accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "import re\n",
        "\n",
        "def extract_video_id(url):\n",
        "    \"\"\"Extracts video ID from different YouTube URL formats.\"\"\"\n",
        "    # We use Regex to hunt for the 11-character ID after 'v=' or 'youtu.be/'\n",
        "    match = re.search(r\"(?:v=|youtu\\.be/)([a-zA-Z0-9_-]{11})\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def get_transcript(video_id):\n",
        "    \"\"\"Fetch transcript using the NEW API format.\"\"\"\n",
        "    try:\n",
        "        api = YouTubeTranscriptApi()\n",
        "        # The .fetch method grabs the subtitle object list\n",
        "        transcript = api.fetch(video_id)\n",
        "        # We join the list into a single long string of text\n",
        "        return \" \".join([t.text for t in transcript])\n",
        "\n",
        "    except TranscriptsDisabled:\n",
        "        return \"Error: Transcripts are disabled for this video.\"\n",
        "    except NoTranscriptFound:\n",
        "        return \"Error: No transcript found for this video.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "RijwpZvMMWRL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Check if we have a GPU (CUDA) available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Switching to BART-Large-CNN for high-quality summarization\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "\n",
        "print(f\"Loading {model_name} on {device}... this might take a minute.\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f241c6a04e774bd686fa0bc27b61e59c",
            "00e1f9cc48ae4c78a00623ad72a4ceaa",
            "a95d3c4728e74308b069243579993afe",
            "4d47cdef5335489d927bcb1290597965",
            "d6aa2017b7ea478392b92ab5a84939f8",
            "c1b47b2e548341c2b498066e00eb2baa",
            "b642dc1a3a814e2a915a710971e80d9f",
            "44b724adb27e4325ae70da63ad4d79db",
            "25c76c6a6ad440dc96c46d5b4b2cdf34",
            "3706cce8285740ffbb44ffbfba09c8db",
            "a53858b1fbaf481b82fa3f4a84ea1b48"
          ]
        },
        "id": "_FxBNL8NMgpq",
        "outputId": "abc98794-f395-4179-e0d2-5f41dc0c5e5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading facebook/bart-large-cnn on cuda... this might take a minute.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/511 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f241c6a04e774bd686fa0bc27b61e59c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_chunk(text_chunk, max_len=150, min_len=40):\n",
        "    # Convert text to tensor numbers (inputs)\n",
        "    inputs = tokenizer(\n",
        "        text_chunk,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate the summary with dynamic length parameters\n",
        "    summary_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_len,     # Dynamic upper limit\n",
        "        min_length=min_len,     # Dynamic lower limit\n",
        "        length_penalty=2.0,     # Encourages longer, more complete thoughts\n",
        "        num_beams=4,            # Explores multiple generation paths\n",
        "        no_repeat_ngram_size=3  # Stops the model from looping\n",
        "    )\n",
        "\n",
        "    # Decode back to text\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "3vrnXj1-M03z"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_words=600, overlap=50):\n",
        "    \"\"\"Splits text by word count to avoid cutting off mid-sentence, with overlap for context.\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "\n",
        "    if len(words) == 0:\n",
        "        return chunks\n",
        "\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        # Grab a larger slice of words to maximize BART's context window\n",
        "        chunk = \" \".join(words[i:i + chunk_words])\n",
        "        chunks.append(chunk)\n",
        "\n",
        "        # Move forward, but step back by the 'overlap' amount\n",
        "        i += (chunk_words - overlap)\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "MoN23lquNDIc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_notes(video_url):\n",
        "    print(f\"\\nüé¨ Processing video: {video_url}\")\n",
        "\n",
        "    video_id = extract_video_id(video_url)\n",
        "    if not video_id:\n",
        "        print(\"Invalid YouTube URL.\")\n",
        "        return\n",
        "\n",
        "    print(\"üéß Fetching transcript...\")\n",
        "    transcript = get_transcript(video_id)\n",
        "\n",
        "    if transcript.startswith(\"Error\"):\n",
        "        print(transcript)\n",
        "        return\n",
        "\n",
        "    # Using the 600-word chunks from Cell 5\n",
        "    print(\"üî™ Chunking transcript...\")\n",
        "    chunks = chunk_text(transcript, chunk_words=600, overlap=50)\n",
        "    print(f\"   -> {len(chunks)} chunks created.\")\n",
        "\n",
        "    print(\"üß† Generating initial notes (Map)...\")\n",
        "    initial_notes = []\n",
        "\n",
        "    # Step 1: Summarize the individual chunks (keep these short and punchy)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"   Summarizing chunk {i+1}/{len(chunks)}...\")\n",
        "        summary = summarize_chunk(chunk, max_len=100, min_len=30)\n",
        "        initial_notes.append(summary)\n",
        "\n",
        "    print(\"‚ú® Generating Master Summary (Reduce)...\")\n",
        "\n",
        "    # Step 2: Combine the mini-summaries\n",
        "    combined_notes = \" \".join(initial_notes)\n",
        "\n",
        "    # Step 3: Chunk the combined notes into medium-sized sections.\n",
        "    # By chunking at 300 words here, we force the model to write a detailed\n",
        "    # paragraph for every ~300 words of initial notes, giving us a longer total output.\n",
        "    final_chunks = chunk_text(combined_notes, chunk_words=300, overlap=0)\n",
        "\n",
        "    final_summary = []\n",
        "    for i, chunk in enumerate(final_chunks):\n",
        "        print(f\"   Writing final section {i+1}/{len(final_chunks)}...\")\n",
        "        # Ask for a longer, detailed summary for the final output\n",
        "        final_summary.append(summarize_chunk(chunk, max_len=250, min_len=80))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìù AI GENERATED MASTER SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Print out nicely formatted paragraphs\n",
        "    for i, paragraph in enumerate(final_summary):\n",
        "        print(f\"\\nPart {i+1}:\\n{paragraph}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    url = input(\"Paste YouTube URL: \")\n",
        "    generate_video_notes(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajtcf3mXNJBA",
        "outputId": "5a7ce981-178b-4bee-e23b-d3520d3e6d88"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste YouTube URL: https://youtu.be/GFuDk8PB1KU?si=oGwTjfLP3IMZV-K6\n",
            "\n",
            "üé¨ Processing video: https://youtu.be/GFuDk8PB1KU?si=oGwTjfLP3IMZV-K6\n",
            "üéß Fetching transcript...\n",
            "üî™ Chunking transcript...\n",
            "   -> 3 chunks created.\n",
            "üß† Generating initial notes (Map)...\n",
            "   Summarizing chunk 1/3...\n",
            "   Summarizing chunk 2/3...\n",
            "   Summarizing chunk 3/3...\n",
            "‚ú® Generating Master Summary (Reduce)...\n",
            "   Writing final section 1/1...\n",
            "\n",
            "==================================================\n",
            "üìù AI GENERATED MASTER SUMMARY\n",
            "==================================================\n",
            "\n",
            "Part 1:\n",
            "Robert Moldun, game warden, easel nubla. park, documented the feeding process for velociaptor anteropus. The big one and her two remaining minions were tranquilized so that our vest could enter the enclosure and inspect the raptor's injuries. She sustained thirdderee burns to all four limbs and lacerations to her mouth before being hurled 40 ft away from the electric fence.\n"
          ]
        }
      ]
    }
  ]
}